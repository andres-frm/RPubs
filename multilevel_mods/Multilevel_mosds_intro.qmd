---
title: "Introduccion modelos jerárquicos (I)"
format: 
  html:
    theme: 
      light: journal
      dark: [journal, theme-dark.scss]
    toc: true
    toc-depth: 10
    toc-expand: 10
    toc-title: "Tabla de contenido"
    toc-location: left
    embed-resources: true
number-sections: true
number-depth: 10
editor: visual
date-format: full 
date-modified: now
mainfont: Times New Roman
code-fold: false
code-overflow: scroll
code-line-numbers: true
code-copy: true
---

```{r, echo=TRUE, results='hide',  warning = F, message = F}

knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

paquetes <- c("rethinking", "tidyverse", "magrittr", 'patchwork', 'rstan',
              'cmdstanr', 'loo')
sapply(paquetes, library, character.only = T)

source('functions_mod_diagnostics.R')

```

# Introducción

Los modelos jerárquicos (mixtos o multinivel), corresponden a un grupo de modelos estadísticos que permiten incorporar explícitamente la jerarquía de la variación en los datos. Esto es, estiman la distribución posterior de los parámetros del modelo a través agrupamientos parciales (*partial pooling*) de los grupos, donde los parámetros particulares de cada grupo se estima de una distribución de probabilidad de la **"poblacional"** de grupos --- i.e. una distribución de probabilidad de coeficientes. Dado que todos los grupos provienen de una misma distribución de probabilidad, las observaciones de un grupo ayudan a estimar los coeficientes de otro. Lo que resulta ventajoso cuando el esfuerzo de muestreo no está balanceado entre grupos. Veamos un ejemplo, aclaremos la idea de agrupamientos en los datos y sus implicaciones para la estimación de los coeficientes en un modelo jerárquico.

Modelemos la probabilidad de supervivencia de huevos en 50 nidadas de una ave cualquiera en un parche de bosque. Tenemos tres alternativas:

<div>

i.  Modelar los datos asumiendo que todos los nidos tienen igual probabilidad $p$ de ser depredados (**pooling**), y por lo tanto estimando un único parámetro común para todos. Esto es, asumimos que la variación entre nidos es cero.

ii. Estimar de manera independiente el coeficiente $p$ para cada nido (**no pooling**).

iii. Estimar $p$ para cada nido, pero asumiendo que cada $p_i$ hace parte de una distribución de probabilidad $Binomial(p)$ de la población de nidos (**partial pooling**).

</div>

Simulemos los datos

```{r}
n <- 50 # número de nidos
set.seed(123)
p <- rbeta(n, 3, 5) # probabilidad real de supervivencia
set.seed(123)
huevos <- sample(rpois(1e3, 10), n) # huevos iniciales
set.seed(123)
y <- rbinom(n, huevos, p) # huevos totales

dat <- list(surv = y,
            huevos = huevos,
            nido = 1:n, 
            N = n)
```

Ajustemos el modelo *pooling*.

```{r, eval=FALSE}
cat(file = 'multilevel_mods/pooling.stan', 
    '
    data{
      int N;
      array[N] int surv;
      array[N] int huevos;
    }
    
    parameters{
      real alpha;
    }
    
    model{
      real p;
      alpha ~ normal(5, 2.5);
      p = alpha;
      p = inv_logit(p);
      surv ~ binomial(huevos, p);
    }
    
    generated quantities{
      vector[N] log_lik;
      real p;
      p = alpha;
      p = inv_logit(p);
      for (i in 1:N) log_lik[i] = binomial_lpmf(surv[i] | huevos[i], p);
    }
    '
    )
```

```{r, results='hide'}

file <- paste(getwd(), '/pooling.stan', sep = '')
fit_pooling <- cmdstan_model(file, compile = T)

pooling <- 
  fit_pooling$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500,
    chains = 3,
    parallel_chains = 3, 
    thin = 3,
    refresh = 500,
    seed = 123
  )

(out_pooling <- pooling$summary())

par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
for (i in 1:2) trace_plot(pooling, out_pooling$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(pooling, out_pooling)

```

Modelo *no pooling*

```{r, eval=FALSE}
cat(file = 'multilevel_mods/no_pooling.stan',
    '
    data{
      int N;
      array[N] int surv;
      array[N] int huevos;
      array[N] int nido;
    }
    
    parameters{
      vector[N] alpha;
    }
    
    model {
      vector[N] p;
      alpha ~ normal(5, 25); // previa para cada nido
    
      for (i in 1:N) {
        p[i] = alpha[nido[i]]; // estimación estratificada por nido
        p[i] = inv_logit(p[i]);
      }
    surv ~ binomial(huevos, p);
      
    }
    
    generated quantities{
      vector[N] log_lik;
      vector[N] p;
      
      for (i in 1:N) {
        p[i] = alpha[nido[i]];
        p[i] = inv_logit(p[i]);
      }
      
      for (i in 1:N) log_lik[i] = binomial_lpmf(surv[i] | huevos[i], p[i]);
    }
    ')
```

```{r, results='hide'}

file <- paste(getwd(), '/no_pooling.stan', sep = '')

fit_no_pooling <- cmdstan_model(file, compile = T)

no_pooling <- 
  fit_no_pooling$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500, 
    chains = 3, 
    parallel_chains = 3, 
    thin = 3, 
    refresh = 500, 
    seed = 123
  )

(out_no_pooling <- no_pooling$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(no_pooling, out_no_pooling$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(no_pooling, out_no_pooling)

```

Modelo *partial pooling*

```{r, eval=FALSE}
cat(file = 'multilevel_mods/par_pooling.stan',
    '
    data{
      int N;
      array[N] int surv;
      array[N] int huevos;
      array[N] int nido;
    }
    
    parameters{
      vector[N] alpha;
      real mu;
      real<lower = 0> sigma;
    }
    
    model{
      vector[N] p;
      alpha ~ normal(mu, sigma); // previa para la población de nidos (previa adaptativa)
      mu ~ normal(5, 2.5); // Hiper previa (previa de la previa)
      sigma ~ exponential(1); // Hiper previa (previa de la previa)
    
      for (i in 1:N) {
        p[i] = alpha[nido[i]]; // modelo estratificado por nido
        p[i] = inv_logit(p[i]);
      }
    
    surv ~ binomial(huevos, p);
    
    }
    
    generated quantities{
      vector[N] log_lik;
      vector[N] p;
      
      for (i in 1:N) {
        p[i] = alpha[nido[i]];
        p[i] = inv_logit(p[i]);
      }
    
      for (i in 1:N) log_lik[i] = binomial_lpmf(surv[i] | huevos[i], p[i]);
    }
    
    ')
```

```{r, results='hide'}

file <- paste(getwd(), '/par_pooling.stan', sep = '')
fit_par_pooling <- cmdstan_model(file, compile = T)

par_pool <- 
  fit_par_pooling$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500,
    chains = 3, 
    parallel_chains = 3, 
    thin = 3, 
    refresh = 500,
    seed = 123
  )

(out_par_pool <- par_pool$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(par_pool, out_par_pool$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(par_pool, out_par_pool)

```

El modelo *partial pooling* recibe el nombre de modelo jerárquico, porque la estimación de los parámetros se realiza en varios niveles. Veamos en notación matemática el modelo anterior:

$$
\begin{align}
&Sup.~huevos_i \sim Binomial(huevos_i,~p_i) & ,~Funcion~de~likelihhod \\
&logit(p_i) \sim \alpha[nido_i] &,~Modelo~lineal \\
&\alpha[nido] \sim Normal(\mu_j, \sigma_j) &,~Previa~para~la~población~de~nidos \\
&\mu_j \sim Normal(5, 2.5) &,~Previa~para~cada~nido~(hiperparámetro) \\ 
&\sigma_j \sim exponential(1) &,~Previa~para~cada~nido~(hiperparámetro) \\ 
\end{align}
$$ 

$\mu_j$ y $\sigma_j$ se conocen como *hiperparámetros* porque son parámetros de parámetros (la previa poblacional), por la misma razón $Normal(5, 2.5)$ y $exponential(1)$ se les llama *hiper-previas*.

Usemos el `looic` para comparar los tres modelos en términos de su capacidad predictiva fuera de la muestra:

```{r}
loo_compare(pooling$loo(), no_pooling$loo(), par_pool$loo())
```

El looic del modelo jerárquico es notablemente más bajo comparado con los modelos *pooling* y *no pooling* (i.e. tiene un mayor poder predictivo). Veamos qué tan precisa es la estimación del log-odds de los modelos jerárquico y *pooling*:

```{r}
log_odds_P <- no_pooling$draws(format = 'df')
log_odds_P <- log_odds_P[, grepl('alpha', colnames(log_odds_P))]
log_odds_parP <- par_pool$draws(format = 'df')

plot(NULL, xlim = c(-5, 5), ylim = c(0, 1.2), xlab = 'log-odds nidos', 
     ylab = 'Densidad')
for (i in 1:500) {
  curve(dnorm(x, log_odds_parP$mu[i], log_odds_parP$sigma[i]), 
        lwd = 0.1, add = T, col = "red")
  lines(density(as.matrix(log_odds_P[i, ])), lwd = 0.1, col = 'tan1')
}

curve(dnorm(x, mean(log_odds_parP$mu), mean(log_odds_parP$sigma)), add = T,
      col = 'red', lwd = 2.5)
lines(density(apply(log_odds_P, 2, mean)), col = 'tan1', lwd = 2.5) 
lines(density(logit(rbeta(1e3, 3, 5))), col = 'black', lwd = 2.5)
```

Ambos modelos predicen bien el promedio del log-odd real (negro). Sin embargo, notemos la amplitud de las distribuciones posteriores, la estimación del modelo jerárquico (rojo) es mucho más precisa comparada con la del modelo *pooling* (naranja).

Ahora comparemos el error de la probabilidad de supervivencia estimada por ambos modelos, con la probabilidad "real" --- la simulada a partir de $Beta(\phi_1 = 3, \phi_2= 5)$.

```{r}
post_parPool <- par_pool$draws(format = 'df')
post_parPool <- as_tibble(post_parPool[, grepl('alpha', colnames(post_parPool))])
colnames(post_parPool) <- paste('nido', 1:n, sep = '')
post_parPool <- do.call('rbind', apply(post_parPool, 2, simplify = 'list', FUN = 
                                         function(x) {
                                           tibble(li = quantile(x, 0.025),
                                                  ls = quantile(x, 0.975),
                                                  mu = mean(x),
                                                  mod = 'Par pooling')
                                         }))

post_parPool$x <- paste('nido', 1:n, sep = '')


post_noPool <- no_pooling$draws(format = 'df')


post_noPool <- as_tibble(post_noPool[, grepl('alpha', colnames(post_noPool))])
colnames(post_noPool) <- paste('nido', 1:n, sep = '')
post_noPool <- do.call('rbind', apply(post_noPool, 2, simplify = 'list', FUN = 
                                        function(x) {
                                          tibble(li = quantile(x, 0.025),
                                                 ls = quantile(x, 0.975),
                                                 mu = mean(x),
                                                 mod = 'No pooling')
                                        }))

post_noPool$x <- paste('nido', 1:n, sep = '')

mods <- rbind(post_noPool, post_parPool)

for (i in 1:3) mods[[i]] <- inv_logit(mods[[i]])

```

```{r, fig.height= 20}
ggplot() +
  geom_errorbar(data = mods, aes(x = x, ymin = li, ymax = ls, color = mod),
                position = position_dodge(width = 0.7), width = 0) +
  geom_point(data = mods, aes(x = x, y = mu, color = mod), 
             position = position_dodge(width = 0.7)) +
  geom_point(data = tibble(y = p, 
                           x = paste('nido', 1:n, sep = '')),
             aes(x, y)) +
  geom_hline(yintercept = mean(p), linetype = 2) +
  labs(y = 'Probabilidad', x = NULL) +
  coord_flip() +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.title = element_blank(), 
        legend.position = 'top')
```

Los puntos negros corresponden a la probabilidad de supervivencia real. Pareciera que los valores predichos por el modelo jerárquico están, en general, más cercanos a la probabilidad de supervivencia real de los nidos. Calculemos este error de estimación y veamos cómo se comporta con el tamaño de la muestra (i.e. número de huevos observados por nido).

```{r}
mods$real_p <- rep(p, 2)
mods$sample_size <- c(huevos, huevos)

mods$error <- mods %$% abs(mu - real_p)

ggplot(mods, aes(sample_size, error, color = mod)) +
  geom_point() +
  geom_smooth(method = 'lm', se = F) +
  labs(x = 'Tamaño de la muestra', y = 'Error P(supervivencia)') +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.title = element_blank(), 
        legend.position = 'top')
```

En ambos modelos el error decrece con el aumento del tamaño de muestra; es natural, más datos por lo general proveen más información y, por lo tanto, una estimación más precisa de los coeficientes. Notemos, sin embargo, que en promedio el modelo jerárquico (*par pooling*) estima la probabilidad de supervivencia con un menor error, aunque para ambos modelos este valor tiende a converger con el incremento del tamaño de muestra.

# Modelos con más de un agrupamiento

En el ejemplo anterior modelamos la probabilidad de supervivencia de huevos en 50 nidadas del ave *X* ubicadas en un parche de bosque cualquiera. Supongamos que la investigadora decidió expandir la investigación, duplicar el número de nidadas analizadas y distribuir su esfuerzo de muestreo en 9 parches de bosques adicionales. Ahora, dado el nuevo diseño, la supervivencia de los huevos no solo varía en función del nido, sino también dado el parche de bosque en el que se encuentra el nido.

Generemos los datos y describamos el modelo en notación matemática:

```{r}
n_nidos <- 100
n_parches <- 10

set.seed(555)
p <- rbeta(n_nidos, 3, 5)# probabilidad de visita (5 min) sin efecto

set.seed(555)
huevos <- rpois(n_nidos, 10)

set.seed(555)
var_parche <- rnorm(1e3, 0, 0.05)

set.seed(555)
var_parche <- sample(var_parche[var_parche >= 0], n_parches, replace = F)
var_parche <- sapply(var_parche, simplify = 'array', FUN = 
                      function(x) rnorm(n_parches, 0, x))
var_parche <- as.vector(var_parche)

set.seed(555)
huevos_obs <- rbinom(n_nidos, 
                     prob = p + var_parche, 
                     size = huevos)
dat <- 
  list(
    n = huevos,
    superv = huevos_obs,
    parche = rep(1:10, each = 10),
    nido = 1:100,
    N = length(huevos),
    N_parche = 10
  )
```

\\

$$
\begin{align}
&Sup.~huevos_i \sim Binomial(huevos_i,~p_i) & ,~Funcion~de~likelihhod \\
&logit(p_i) \sim \alpha[nido_i] + \psi[parche] &,~Modelo~lineal \\ 
&\psi[parche] \sim Normal(0, \tau) &,~Previa variación~entre~parches\\
&\tau \sim exponential(1) &, ~ Hiper-parámetro/previa~de~la~previa~del~parche\\
&\alpha[nido] \sim Normal(\mu_j, \sigma_j) &,~Previa~para~la~población~de~nidos \\
&\mu_j \sim Normal(5, 2.5) &,~Previa~para~cada~nido~(hiperparámetro) \\ 
&\sigma_j \sim exponential(1) &,~Previa~para~cada~nido~(hiperparámetro) \\ 
\end{align}
$$

El parche corresponde a un factor que altera la supervivencia de los huevos. Es decir, $p_i$ reduce o aumenta en función del parche. Dichas oscilaciones las incorporamos en el modelo en forma de una distribución $Normal(0, \tau)$, donde $\tau$ controla la 'magnitud' de los cambios positivos o negativos.

Ajustemos el modelo:

```{r, eval =FALSE}
cat(file = 'multilevel_mods/par_pooling2.stan',
    '
    data{
      int N;
      int N_parche;
      array[N] int n;
      array[N] int superv;
      array[N] int parche;
      array[N] int nido;
    }
    
    parameters{
      vector[N] alpha;
      vector[N_parche] tau;
      real muA;
      real<lower = 0> sigmaA;
      real<lower = 0> sigmaT;
    }
    
    model{
      vector[N] p;
      alpha ~ normal(muA, sigmaA);
      tau ~ normal(0, sigmaT);
      muA ~ normal(5, 2.5);
      sigmaA ~ exponential(1);
      sigmaT ~ exponential(1);
    
      for (i in 1:N) {
        p[i] = alpha[nido[i]] + tau[parche[i]];
        p[i] = inv_logit(p[i]);
      }
      
      superv ~ binomial(n, p);
    
    }
    
    generated quantities {
      vector[N] log_lik;
      vector[N] p;
    
    for (i in 1:N) {
        p[i] = alpha[nido[i]] + tau[parche[i]];
        p[i] = inv_logit(p[i]);
    }
    
    for (i in 1:N) log_lik[i] = binomial_lpmf(superv[i] | n[i], p[i]);
    }
    ')

```

```{r, results='hide'}

file <- paste(getwd(), '/par_pooling2.stan', sep = '')

fit_par_pooling2 <- cmdstan_model(file, compile = T)

mod <- 
  fit_par_pooling2$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500,
    chains = 3,
    parallel_chains = 3,
    thin = 3,
    refresh = 500,
    seed = 123
  )

```

```{r}
(out_par_pool2 <- mod$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(mod, out_par_pool2$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(mod, out_par_pool2)

```

Tenemos un parámetro por cada nido, uno por cada parche y su parámetro de dispersión y la probabilidad de supervivencia promedio. Antes de discutir las implicaciones de los parámetros, grafiquemos las distribuciones predictivas posteriores y estimemos la precisión del modelo para representar las observaciones.

```{r}
post <- mod$draws(format = 'df')

post <- post[, 2:112]

post <- as.data.frame(apply(post, 2, inv_logit))

ppcheck <- sapply(1:100, simplify = 'array', FUN = 
                    function(x) rbinom(1e3, 
                                       size = dat$n, 
                                       prob = post$muA[i]))

plot(NULL, xlim = c(-1, 10), ylim = c(0, 0.6))
for (i in 1:100) lines(density(ppcheck[i, ]), lwd = 0.15, col = 'blue')
lines(density(dat$superv), col = 'red', lwd = 3)
abline(v = c(mean(apply(ppcheck, 2, mean)), mean(dat$superv)), 
       col = c('blue', 'red'), lty = 3)
```

El modelo se ajusta adecuadamente a los datos, incluso el promedio estimado de huevos supervivientes es básicamente igual al observado.

Veamos las implicaciones de los parámetros

```{r}
par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
plot(NULL, xlim = c(0, 1), ylim = c(0, 6), xlab = expression(italic('P')['nido']),
     ylab = 'Densidad', main = 'Nido')
for (i in 1:100) lines(density(post[, grep('alpha', colnames(post))][[i]]), lwd = 0.2)
lines(density(apply(post[, grep('alpha', colnames(post))], 2, mean)), lwd = 3, col = 'red')
lines(density(p + var_parche), lwd = 3, col = 'blue')
post2 <- mod$draws(format = 'df')
post2 <- post2[, grepl('sigma', colnames(post2))]
plot(density(post2$sigmaA), main = "Parche", xlim = c(0, 1.5), 
     xlab = expression(sigma[italic(P)]), ylab = '',
     ylim = c(0, 4.5))
lines(density(post2$sigmaT), lty = 2)
par(mfrow = c(1, 1))
```

**Izquierda**. Cada línea de densidad negra corresponde a la distribución posterior de $p$ para cada nido, la línea roja denota el promedio entre nidos ---igual que el parámetro $\mu_i$ en el modelo, y la línea azul corresponde a la probabilidad real (i.e. probabilidad de supervivencia, $Beta(3, 5)$, más variación dado el parche, $Normal(0, \tau)$). **Derecha**. Distribución posterior de los parámetros de dispersión de los nidos (línea sólida) y los parches (línea discontinua).

La probabilidad de supervivencia promedio es del *\~40%*.

```{r}
mean(apply(post[, grepl('alpha', colnames(post))], 2, mean))
```

De hecho, el modelo fue capaz de recuperar la distribución de probabilidad generadora de los datos (línea azul). También, con seguridad, podemos afirmar que la variación en la probabilidad de supervivencia entre nidos es mayor a la producida por los diferentes parches. Podríamos generar un nuevo modelo sin el factor parche, compararlos con `looic`, y evaluar el aporte del parche en la capacidad predictiva del modelo.

Podríamos concluir (ponele...), que los factores que determinan la probabilidad de supervivencia de huevos en nidos del ave `X` operan principalmente a escala local ---la principal variación proviene del `nido`, mientras que el aporte del `parche` es tangencial. **Supongamos que la investigadora alcanzó la misma conclusión y, en un intento de identificar dichos factores locales moduladores de la supervivencia, decidió medir la proporción de cobertura vegetal en un radio de 1 m alrededor de cada nido. Veamos:**

# Transiciones divergentes y reparametrización

De nuevo simulemos los datos y definamos el modelo.

```{r}
n_nidos <- 100
n_parches <- 10

set.seed(555)
p <- rbeta(n_nidos, 3, 5)

set.seed(555)
huevos <- rpois(n_nidos, 10)

set.seed(555)
var_parche <- rnorm(1e3, 0, 0.1)

set.seed(555)
var_parche <- sample(var_parche[var_parche >= 0], n_parches, replace = F)
var_parche <- sapply(var_parche, simplify = 'array', FUN = 
                       function(x) rnorm(n_parches, 0, x))
var_parche <- as.vector(var_parche)

tot_p <- p + var_parche

set.seed(555)
pro_veg <- rbeta(1e3, 2, 1.5)

temp2 <- quantile(pro_veg, probs = seq(0, 1, by = 0.2))
temp <- quantile(tot_p, probs = seq(0, 1, by = 0.2))

veg <- vector('double', 100)

set.seed(555)
for (i in 1:(length(temp)-1)) {
  veg[which(tot_p >= temp[i] & tot_p <= temp[i+1])] <- 
    sample(pro_veg[pro_veg > temp2[i] & pro_veg <= temp2[i+1]], 
           size = length(which(tot_p >= temp[i] & tot_p <= temp[i+1])), 
           replace = F) + 
    rnorm(length(which(tot_p >= temp[i] & tot_p <= temp[i+1])), 
          0, 0.05)
}

set.seed(555)
beta_veg <- 0.1

set.seed(555)
huevos_obs <- rbinom(n_nidos, 
                     prob = p + var_parche + beta_veg*veg, 
                     size = huevos)
dat <- 
  list(
    n = huevos,
    superv = huevos_obs,
    parche = rep(1:10, each = 10), 
    prop_veg = veg,
    nido = 1:100,
    N = length(huevos),
    N_parches = 10
  )

```

En principio, ajustemos el modelo anterior, pero incluyamos un parámetro $\beta$ que controle la relación entre la supervivencia de huevos y la proporción de cobertura vegetal. Esto es:

$$
\begin{align}
&Supervivencia_i \sim Binomial(huevos_i,~p_i) \\
&logit(p_i) \sim \alpha[nido_i] + \psi[parche] + \beta\times{prop. vegetación}\\
&\beta \sim Normal(0.5, 1)\\
&\psi[parche] \sim Normal(0, \tau) \\
&\tau \sim exponential(1) \\
&\alpha[nido] \sim Normal(\mu_j, \sigma_j) \\
&\mu_j \sim Normal(5, 2.5) \\ 
&\sigma_j \sim exponential(1) \\ 
\end{align}
$$

```{r, eval = F}
cat(file = 'par_pooling3.stan', 
    '
    data{
      int N;
      int N_parches;
      array[N] int n;
      array[N] int superv;
      array[N] int parche;
      vector[N] prop_veg;
      array[N] int nido;
    }
    
    parameters{
      vector[N] alpha;
      vector[N_parches] psi;
      real mu;
      real beta;
      real<lower = 0> sigma;
      real<lower = 0> tau;
    }
    
    model {
      vector[N] p;
      
      for (i in 1:N) {
        p[i] = alpha[nido[i]] + psi[parche[i]] + beta*prop_veg[i];
        p[i] = inv_logit(p[i]);
      }
    
      alpha ~ normal(mu, sigma);
      psi ~ normal(0, tau);
      mu ~ normal(10, 5);
      beta ~ normal(0.5, 1);
      sigma ~ exponential(1);
      tau ~ exponential(1);
    
      superv ~ binomial(n, p);
    
    }
    
    generated quantities{
      vector[N] log_lik;
      vector[N] p;
    
      for (i in 1:N){
        p[i] = alpha[nido[i]] + psi[parche[i]] + beta*prop_veg[i];
        p[i] = inv_logit(p[i]);
      }
    
      for (i in 1:N) log_lik[i] = binomial_lpmf(superv[i] | n[i], p[i]);
    }
    ')
```

```{r, warning=T, results='hide'}
file <- paste(getwd(), '/par_pooling3.stan', sep = '')

fit_par_pooling3 <- cmdstan_model(file, compile = T)

mod2.1 <- 
  fit_par_pooling3$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500,
    chains = 3,
    parallel_chains = 3,
    thin = 3,
    refresh = 500,
    seed = 123
  )

(out_par_pool3 <- mod2.1$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(mod2.1, out_par_pool3$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(mod2.1, out_par_pool3)

```

```{r}
sum(mod2.1$sampler_diagnostics(format = 'df')$divergent__)
```

El modelo tiene un un número tal de transiciones divergente que el *effective sampling size* de algunos parámetros es inferior a 1000 y por lo tanto no deberíamos estar muy confiados de esta estimación. Esto es común en modelos jerárquicos, y sucede porque el algoritmo explora incorrectamente algunas regiones del espacio de los parámetros. Podríamos intentar solucionarlo de varias formas: (i) incrementando el número de iteraciones (no es lo ideal porque no lidiaríamos con el problema de eficiencia en la exploración del algoritmo); (ii) incrementando la tasa de aceptación de valores que explora el algoritmo controlando los "saltos" entre uno y otro valor estimado (leapfrog step); (iii) reparametrización del modelo. Probemos la alternativa *ii* incrementando el `adapt_delta = 0.99`:

```{r, warning=T, results='hide'}
mod2.2 <- 
  fit_par_pooling3$sample(
    data = dat,
    iter_sampling = 2e3,
    iter_warmup = 500,
    chains = 3,
    parallel_chains = 3,
    thin = 3,
    refresh = 500,
    seed = 123,
    adapt_delta = 0.99
  )
  
(out_par_pool4 <- mod2.2$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(mod2.2, out_par_pool4$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(mod2.1, out_par_pool3)

```

Bien, tenemos menos transiciones divergentes, pero el *effective sampling size* continua bajo para algunos coeficientes. Probemos entonces reparametrizando el modelo, específicamente una reparametrización no centrada (non-centered reparametrization). Esta consiste en una estandarización que permite que el algoritmo explore el espacio de los parámetros de manera más eficiente. Veamos:

```{r, eval=FALSE}
cat(file = 'par_pooling4.stan',
    '
    data{
      int N;
      int N_parches;
      array[N] int n;
      array[N] int superv;
      array[N] int parche;
      vector[N] prop_veg;
      array[N] int nido;
    }
    
    parameters{
      vector[N] z_alpha;
      vector[N_parches] z_psi;
      real mu1;
      real mu2;
      real beta;
      real<lower = 0> sigma;
      real<lower = 0> tau;
    }
    
    model{
      vector[N] p;
      vector[N] alpha;
      vector[N_parches] psi;
      mu1 ~ normal(10, 5);
      mu1 ~ normal(0, 5);
      z_alpha ~ normal(0, 1);
      z_psi ~ normal(0, 1);
      sigma ~ exponential(1);
      tau ~ exponential(1);
      beta ~ normal(0.5, 1);
      alpha = mu1 + z_alpha*sigma;
      psi = mu2 + z_psi*tau;
    
      for (i in 1:N) {
        p[i] = alpha[nido[i]] + psi[parche[i]] + beta*prop_veg[i];
        p[i] = inv_logit(p[i]);
      }
    
      superv ~ binomial(n, p);
    
    }
    
    generated quantities{
      vector[N] log_lik;
      vector[N] p;
      vector[N] alpha;
      vector[N_parches] psi;
      alpha = mu1 + z_alpha*sigma;
      psi = mu2 + z_psi*tau;
    
      for (i in 1:N) {
        p[i] = alpha[nido[i]] + psi[parche[i]] + beta*prop_veg[i];
        p[i] = inv_logit(p[i]);
      }
    
      for (i in 1:N) log_lik[i] = binomial_lpmf(superv[i] | n[i], p[i]);
    }
    ')
```

```{r, warning=TRUE, results='hide'}
file <- paste(getwd(), '/par_pooling4.stan', sep = '')
fit_par_pooling4 <- cmdstan_model(file, compile = T)

mod2.3 <- 
  fit_par_pooling4$sample(
    data = dat,
    iter_warmup = 500,
    iter_sampling = 2e3,
    chains = 3,
    parallel_chains = 3,
    thin = 3,
    refresh = 500,
    seed = 123
  )

(out_par_pool5 <- mod2.3$summary())
par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(mod2.3, out_par_pool5$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(mod2.3, out_par_pool5)

```

Las transiciones divergentes persisten, pero ahora tenemos suficientes estimados de los parámetros estadísticamente independientes.

Veamos ahora el ajuste a los datos del modelo reparametrizado (i.e. distribución predictiva posterior). Además, verifiquemos que podemos recobrar la distribución de probabilidad generadora de los datos ($Beta(3, 5)~+~\sigma,~\sigma \sim Normal(0, \phi)$)

```{r}
post <- mod2.3$draws(format = 'df')

est_p <- sapply(1:100, simplify = 'array', FUN = 
                  function(i) {
                    
                    # equivalente a usar link(mod2.3, dat)
                    
                    i_alpha <- dat$nido[i]
                    i_psi <- dat$parche[i]
                    
                    p <- post[, grepl('^alpha', colnames(post))][[i_alpha]] +
                      post[, grepl('^psi', colnames(post))][[i_psi]] + 
                      (post$beta*dat$prop_veg[i])
                    
                    inv_logit(p)
                    
                  })


est <- sapply(1:100, simplify = 'array', FUN = 
                function(x) {
                  i_alpha <- dat$nido[x]
                  i_psi <- dat$parche[x]
                  
                  p <-
                    post[, grepl('^alpha', colnames(post))][[i_alpha]] +
                    post[, grepl('^psi', colnames(post))][[i_psi]] +
                    (post$beta*dat$prop_veg[i])
                  
                  rbinom(1e3, size = dat$n[x], prob = inv_logit(p))
                  # equivalente a sim(mod2.3, dat)
                })


```

En efecto el modelo está adecuadamente definido.

Comparemos ahora las distribuciones posteriores por nido y parche

```{r, warning=FALSE}
par(mfrow = c(1, 3), mar = c(4, 4, 1, 1))
plot(density(dat$superv), ylim = c(0, 0.25), main = 'ppchecks', 
     xlab = 'N huevos')
for (i in 1:100) lines(density(est[i, ]), lwd = 0.1)
lines(density(dat$superv), col = 'red', lwd = 3)
plot(NULL, xlim = c(0, 1), ylim = c(0, 4), ylab = 'Densidad', 
     xlab = expression(italic(P)['nido']))
for (i in 1:100) {
  lines(density(inv_logit(post[, grepl('alpha', colnames(post))][[i]])), 
        lwd = 0.3)
}
plot(NULL, xlim = c(0, 1), ylim = c(0, 4), ylab = 'Densidad', 
     xlab = expression(italic(P)['parche']))
for (i in 1:10) {
  lines(density(inv_logit(post[, grepl('psi', colnames(post))][[i]])), 
        lwd = 0.3)
}
par(mfrow = c(1, 1))
```

La probabilidad de supervivencia de los huevos es notablemente más variable entre nidos.

Ya sabemos que la cobertura vegetal tiene un efecto positivo sobre la supervivencia de los huevos, nosotros la simulamos, pero veamos sus implicaciones para el modelo.

```{r}
v <- seq(0, 1, length.out = 100)

b_veg <- sapply(1:100, simplify = 'array', FUN = 
                  function(i) {
                    inv_logit(post$beta*v[i])
                  })

ci_veg <- apply(b_veg, 2, quantile, c(0.025, 0.975))

plot(v, apply(b_veg, 2, mean), type = 'l', xlab = 'Cobertura de vegetación (prop)', 
     ylab = 'Probabilidad de supervivencia') 
shade(ci_veg, v, col = col.alpha('cyan4'))

```

Graficamos el efecto neto de la cobertura vegetación, también podríamos estratificarlo por cada nido o parche de bosque.

# Ejemplo

Las simulaciones estocásticas nos permite plantear el modelo generador de los datos y estudiar el desempeño de un modelo estadístico, sus supuestos y alcances, para recuperar dichos parámetros iniciales. Es sin duda ilustrativo. Ahora, apliquemos lo ya expuesto a un set de datos empírico. En este caso usaremos datos de un censo de fertilidad, específicamente el uso de anticonceptivos por mujeres bengalíes (Bangladesh) en 1988. Carguemos `rethinking::bangladesh` y exploremos las variables:

```{r}
data(bangladesh)
d <- bangladesh

d$district_id <- as.integer(as.factor(d$district))

colnames(d)
```

`d` contiene 6 variables:

<div>

-   `woman`: identificador de la mujer.

-   `distric`: distrito al que pertenece.

-   `use.contraception`: uso (1) o no (0) de anticonceptivos.

-   `living.children`: número de hijos vivos.

-   `age.centered`: edad centrada.

-   `urban`: contexto urbano (1) o no urbano (0). En nuestro caso lo llamaremos rural.

</div>

Nuestro objetivo será evaluar cómo el distrito, el contexto y la edad, modulan la probabilidad de que una mujer bengalí, en 1988, usara un método anticonceptivo. Definamos primero el modelo en notación matemática:

$$
\begin{align}
&Uso~anticonceptivos \sim Binomial(1, P) \\
&logit(P_i) = \alpha_{urbano_i} + \theta_{distrito_i} + \beta\times edad \\
&\alpha_{urbano_i} \sim Normal(\mu, \sigma) \\
&\theta_{distrito_i} \sim Normal(0, \phi) \\
&\mu \sim Normal(0, 3) \\
&\sigma \sim exponential(1) \\
&\phi \sim exponential(1)\\
&\beta \sim Normal(0.5, 0.2)
\end{align}
$$ Detengámonos un momento en las probabilidades previas, y discutamos mi razonamiento para su elección. Los centros urbanos en general tienen un mayor acceso a establecimientos educativos y de salud. Sería razonable esperar que la probabilidad de usar anticonceptivos sea más baja en contextos rurales comparada con los urbanos. La previa $\mu \sim Normal(0, 3)$ implica justamente esto en la escala logit y de probabilidad, veamos:

```{r}
par(mfrow = c(1, 2))
curve(dnorm(x, 0, 1.5), xlim = c(-5, 5), xlab = 'Log-odds(P)', ylab = 'Density')
plot(density(inv_logit(rnorm(1e3, 0, 1.5))), xlab = 'P', ylab = 'Density', 
     main = '')
par(mfrow = c(1, 1))
```

Esta previa permite que el algoritmo explore, en escala logit, tanto valores negativos como positivos restringidos a $-3$ y $+3$. En probabilidades, implica todo el rango de probabilidades entre 0 y 1.

El contexto social, embebido en el espacial, probablemente modula la elección que hacen las mujeres. Esto es, más allá de vivir en un ambiente rural o urbano, variaciones en el sistema de creencias entre las comunidades en las que viven las mujeres, nos llevarían a esperar oscilaciones en la probabilidad de uso de anticonceptivos de acuerdo al distrito. La previa que hace justamente incorpora dicha variación eso $\theta_{distrito_i} \sim Normal(0, \phi)$.

Finalmente, con el tiempo llegan la experiencia, madurez, la introspección (**PONELE**). Sea por razones éticas, ambientales, filosóficas o simplemente cansancio, es razonable suponer que la probabilidad de usar métodos anticonceptivos es mayor en mujeres más adultas. Por lo tanto, empleamos $\beta \sim Normal(0.15, 0.2)$ una previa que permite al algoritmo explorar principalmente valores positivos de $\beta$, pero permaneciendo relativamente conservador. Veamos:

```{r}
betas_i <- rnorm(100, 0.15, 0.2)
plot(NULL, xlim = c(-10, 10), ylim = c(0, 1), xlab = 'Edad', ylab = 'Probabilidad')
for (i in 1:100) curve(inv_logit(0 + betas_i[i]*x), add = T, lwd = 0.1)
curve(inv_logit(0 + mean(betas_i)*x), add = T, lwd = 2, col = 'red')
```

Una vez definidas las previas, agrupemos las variables en una lista y ajustemos el modelo:

```{r, eval = FALSE}
cat(file = 'multilevel_mods/par_pooling5.stan', 
    '
    data{
      int N;
      int N_distrito;
      int N_urbano;
      int N_anticonc;
      array[N] int anticonc;
      array[N] int distrito;
      array[N] int urbano;
      //vector[N] edad;
    }
    
    parameters{
      vector[N_distrito] z_alpha;
      vector[N_distrito] z_beta;
      real beta1;
      real alpha1;
      real<lower = 0> sigma;
      real<lower = 0> phi;
    }
    
    model{
      vector[N] p;
      vector[N_distrito] alpha;
      vector[N_distrito] beta;
      alpha1 ~ normal(0, 1);
      z_alpha ~ normal(0, 1);
      sigma ~ exponential(1);
      beta1 ~ normal(0, 1);
      z_beta ~ normal(0, 1);
      phi ~ exponential(1);
      alpha = alpha1 + z_alpha*sigma;
      beta = beta1 + z_beta*phi;
    
      for (i in 1:N) {
        p[i] = alpha[distrito[i]] + beta[distrito[i]]*urbano[i]; 
        p[i] = inv_logit(p[i]);
      }
    
      anticonc ~ binomial(1, p);
    
    }
    
    generated quantities{
      vector[N] log_lik;
      vector[N] p;
      vector[N_distrito] alpha;
      vector[N_distrito] beta;
      alpha = alpha1 + z_alpha*sigma;
      beta = beta1 + z_beta*phi;
    
      for (i in 1:N) {
        p[i] = alpha[distrito[i]] + beta[distrito[i]]*urbano[i]; 
        p[i] = inv_logit(p[i]);
      }
    
      for (i in 1:N) log_lik[i] = binomial_lpmf(anticonc[i] | 1, p[i]);
    }
    ')
```

```{r, results='hide'}
dat <- 
  list(
    anticonc = d$use.contraception,
    urbano = as.integer(ifelse(d$urban == 1, 1, 2)),
    distrito = d$district_id,
    edad = d$age.centered,
    N = nrow(d),
    N_distrito = length(unique(d$district_id)),
    N_urbano = 2,
    N_anticonc = 2
  )

file <- paste(getwd(), '/par_pooling5.stan', sep = '')

fit_par_pooling5 <- cmdstan_model(file, compile = T)

me2 <- 
  fit_par_pooling5$sample(
    data = dat,
    iter_sampling = 4e3,
    iter_warmup = 500,
    parallel_chains = 3, 
    chains = 3,
    thin = 3,
    seed = 123,
    refresh = 500
  )


(out_par_pool6 <- me2$summary())

par(mfrow = c(3, 3), mar = c(4, 4, 1, 1))
for (i in 1:9) trace_plot(me2, out_par_pool6$variable[i], 3)
par(mfrow = c(1, 1))

mod_diagnostics(me2, out_par_pool6)

```

Todos los parámetros tienen más de mil estimados estadísticamente independientes y `Rhat ~ 1`. Podríamos ---más bien deberíamos, graficar las cadenas para corroborar que convergieron a la misma distribución posterior y exploraron el mismo espacio del parámetro. Pero, en este caso, confiaremos en la *salida* del modelo.

Verifiquemos el ajuste del modelo a los datos:

```{r}
post2 <- me2$draws(format = 'df')

ppcheck <- sapply(1:length(dat$anticonc), simplify = 'array', FUN = 
                    function(x) {
                      urbano <- dat$urbano[x]
                      distrito <- dat$distrito[x]
                      
                      p <- 
                        post2[, grepl('^alpha', colnames(post2))][[distrito]] + 
                        post2[, grepl('^beta', colnames(post2))][[distrito]]*urbano 
                      
                      rbinom(1e3, 1, inv_logit(p))
                      
                    })

plot(NULL, xlim = c(-0.3, 1.3), ylim = c(0, 3.2), 
     xlab = 'Uso de anticonceptivo', ylab = 'Densidad')
for (i in 1:200) lines(density(ppcheck[i, ]), lwd = 0.1)
lines(density(dat$anticonc), col = 'red', lwd = 2)
```

El modelo es confiable. Grafiquemos ahora los efectos condicionales, y verifiquemos las implicaciones del distrito y el contexto espacial en la probabilidad de que las mujeres usen algún método anticonceptivo. Primero realicemos cálculos y un poco de carpintería:

```{r}

bar_urb <- unique(tibble(dist = dat$distrito,
                         urb = dat$urbano))

post_urb_dist <- sapply(1:nrow(bar_urb), simplify = 'array', FUN = 
                          function(x) {
                            
                            dist <- bar_urb$dist[x]
                            urb <- bar_urb$urb[x]
                            
                            p <- post2[, grepl('^alpha', colnames(post2))][[dist]] +
                              post2[, grepl('^beta', colnames(post2))][[dist]]*urb
                            
                            inv_logit(p)
                            
                          })

bar_urb$level <- ifelse(bar_urb$urb == 1, 'Urbano', 'Rural')

post_urb_dist <- as_tibble(post_urb_dist)

colnames(post_urb_dist) <- paste(bar_urb$level, bar_urb$dist, sep = '')

post_urb_dist <- gather(post_urb_dist)

alpha_urb <- post_urb_dist

post_urb_dist <- 
  post_urb_dist |> 
  group_by(key) |> 
  transmute(li = quantile(value, 0.025), 
            ls = quantile(value, 0.975),
            mu = mean(value)) |> 
  ungroup() |> 
  unique()

post_urb_dist$dist <- gsub('^([aA-zZ]*)([0-9]{1,})', '\\2', post_urb_dist$key)
post_urb_dist$factor <- gsub('^([aA-zZ]*)([0-9]{1,})', '\\1', post_urb_dist$key)

alpha_urb$key <- ifelse(grepl('^Urban', alpha_urb$key), 'Urbano', 'Rural')

contraste <- split(alpha_urb, alpha_urb$key)
contraste <- tibble(x = sample(contraste$Urbano$value, 1e4) - sample(contraste$Rural$value, 1e4))

```

Ahora el gráfico

```{r, fig.height= 10}
plot_contraste <- 
  ggplot(contraste, aes(x)) +
  geom_density(fill = 'seagreen', color = 'seagreen', alpha = 0.5) +
  labs(x = quote(italic(P['(Diferencia urbano-rural)'])), y = 'Densidad') +
  geom_vline(xintercept = mean(contraste$x), linetype = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        text = element_text(family = 'Times New Roman'))

plot_cond <- 
  post_urb_dist |> 
  ggplot(aes(xmin = li, xmax = ls, x = mu, 
             y = fct_reorder(dist, mu, .desc = T), color = factor)) +
  geom_point(position = position_dodge(width = 0.3)) +
  geom_linerange(position = position_dodge(width = 0.3)) +
  labs(x = quote(italic(P['(usar anticonceptivos)'])), y = 'Distrito') +
  theme_bw() +
  theme(panel.grid = element_blank(), 
        legend.title = element_blank(), 
        legend.position = 'top',
        text = element_text(family = 'Times New Roman'))

plot_contraste + 
  plot_cond + 
  plot_layout(ncol = 2)

```

Concluimos que las mujeres en zonas urbanas tienen, en general, un 15% más de probabilidad de usar anticonceptivos comparadas con mujeres en ambientes rurales (figura izquierda). Pero también observamos que, además del contexto espacial, dicha probabilidad está fuertemente influenciada por el distrito (figura derecha).

Podría dedicar una sección a discutir las implicaciones de los resultados para una intervención, distrito específica, para fomentar el uso de anticonceptivos en mujeres bengalíes allá en 1988, pero no es el objetivo del ejercicio. Eso se lo dejo a quién sea que haya llegado hasta acá.

```{r}
sessionInfo()
```
